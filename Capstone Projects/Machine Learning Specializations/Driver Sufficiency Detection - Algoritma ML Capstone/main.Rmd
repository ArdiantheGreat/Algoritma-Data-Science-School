---
title: "There is no drivers!"
author: "Ardian"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float:
      collapsed: true
---

#### **Import library** yang digunakan
```{r message=FALSE}
library(dplyr)
library(lubridate)
library(padr)
library(e1071)
library(caret)
library(partykit)
library(randomForest)
library(reshape2)
library(tidyverse)
library(tidymodels)
library(lime)
library(rmarkdown)
```

#### **Baca data** train
```{r}
train <- read.csv("data_input/data-train.csv")

train %>% head()
```
                                                                       
## DATA PRE-PROCESSING
  
#### Periksa **duplikat** dan **missing value**                                                                     
```{r}
train %>% anyDuplicated()
train %>% anyNA()
train %>% is.na() %>% colSums()
train$status %>% table() %>% prop.table()
```
Tidak ada duplicated data, namun terdapat missing value. Kabar baiknya, missing value pada kedua kolom tersebut dikarenakan tidak adanya driver, yang di mana informasi tersebut sudah diwakili oleh kolom *status* dengan nilai "nondrivers"

#### **Drop kolom** selain *start_time*, *src_area*, dan *status*
Ternyata, setelah saya lihat, data test hanya terdapat input *src_area* dan *start_time*. Karena itu, saya akan drop semua kolom selain dua kolom tersebut dan juga kolom *status*. Kolom *status* akan menjadi penentu apakah lokasi *src_area* pada waktu tertentu terdapat jumlah driver yang **sufficient** atau tidak. Nantinya, saya akan mengekstrak informasi *dhour* dan *wday* dari kolom *start_time* untuk dijadikan features
```{r}
train <- train %>% select(start_time, src_area, status)

train %>% head(3)
```

#### Ubah **tipe data** kolom
Kita perlu mengubah tipe data ketiga kolom kita, yaitu:
  1. Kolom *start_time* datetime
  2. Kolom *src_area* dan *status* menjadi factor
Saya juga **mengubah nama kolom** *start_time* menjadi *date_time*
```{r}
train <- train %>% 
  mutate(start_time = floor_date(ymd_hms(start_time), unit = "hour")) %>% 
  mutate_if(is.character, as.factor) %>% 
  rename(datetime = start_time) %>% 
  arrange(datetime)

train %>% head(3)
```

#### **Agregasi** data
Kita melakukan agregasi data untuk mendapatkan informasi jumlah transaksi untuk setiap pasangan *src_area*, *date_time*, dan *status*
```{r}
train <- train %>%
  group_by(src_area, datetime, status) %>% 
  summarise(count = n()) %>% 
  arrange(src_area, datetime)

train %>% head()
```

#### **Filter** untuk transaksi dengan status **no_drivers**
```{r}
train <- train %>% 
  filter(status == "nodrivers") %>% 
  select(-status)

train %>% head(3)
```

#### **Pad** data agar semua *src_ara* mendapatkan pasangan *datetime* yang lengkap
```{r message=FALSE, warning=FALSE}
train <- train %>%
  group_by(src_area) %>%
  summarise(datetime = seq(min(datetime), max(datetime), by = "hour")) %>%
  pad() %>%
  left_join(train, by = c("src_area", "datetime")) %>%
  arrange(src_area, datetime) %>% 
  mutate(count = ifelse(is.na(count), 0, count))

train %>% head(3)
```

#### Membuat kolom **coverage**
**Coverage** bernilai "insufficient" apabila *count* lebih dari 0 dan sebaliknya
```{r}
train <- train %>% 
  mutate(coverage = ifelse(count != 0, "insufficient", "sufficient") %>% as.factor(),
         dhour = as.factor(hour(datetime)),
         wday = as.factor(wday(datetime))) %>% 
  select(-count, -datetime) %>% 
  as.data.frame()

train %>% head()
```

## EXPLORATORY DATA ANALYSIS
                                                                    
#### Cek **proporsi** *coverage* secara **kesuluruhan**                                                                    
```{r}
train$coverage %>% table() %>% prop.table() %>% barplot()
```

#### Cek **proporsi** *coverage* per *src_area*
```{r}
for (area in unique(train$src_area)){
  filter(train, src_area == area)$coverage %>%
          table() %>% 
          prop.table() %>% 
          barplot(main = area)
}
```
Tidak balance pada "sxk8" dan "sxk9"

Apakah saya akan melakukan upsampling untuk setiap area? Tidak. Karena, sebelumnya saya sudah coba lakukan dan performa modelnya tidak sebagus tanpa upsampling. Berikut cara saya upsampling pada percobaan sebelumnya:
```{r}
# up_sxk3 <- upSample(
#   x = train %>% filter(src_area == "sxk3") %>% select(-coverage),
#   y = train[train$src_area == "sxk3", "coverage"]
# )
# 
# up_sxk8 <- upSample(
#   x = train %>% filter(src_area == "sxk8") %>% select(-coverage),
#   y = train[train$src_area == "sxk8", "coverage"]
# )
# 
# up_sxk9 <- upSample(
#   x = train %>% filter(src_area == "sxk9") %>% select(-coverage),
#   y = train[train$src_area == "sxk9", "coverage"]
# )
# 
# # Gabungkan seluruh hasil upsample
# up_train <- bind_rows(up_sxk3, up_sxk8, up_sxk9)
```

#### Cek **kolerasi** antara ketiga *features* dengan *coverage*
```{r}
ggplot(train, aes(x = src_area, fill = coverage)) +
  geom_bar(position = "stack") +
  scale_fill_manual(values = c("pink", "lightgreen")) +
  labs(title = "Coverage by src_area") +
  theme_minimal()

ggplot(train, aes(x = dhour, fill = coverage)) +
  geom_bar(position = "stack") +
  scale_fill_manual(values = c("pink", "lightgreen")) +
  labs(title = "Coverage by dhour") +
  theme_minimal()

ggplot(train, aes(x = wday, fill = coverage)) +
  geom_bar(position = "stack") +
  scale_fill_manual(values = c("pink", "lightgreen")) +
  labs(title = "Coverage by wday") +
  theme_minimal()
```

#### Cek **distribusi** *coverage* per *src_area* pada setiap *wday* dan *dhour*
```{r}
for (feature in c("dhour", "wday")) {
  print(
    ggplot(train, aes(x = get(feature), fill = coverage)) +
      geom_bar(position = "stack") +
      scale_fill_manual(values = c("pink", "lightgreen")) +
      facet_wrap(~ src_area) +
      labs(title = paste("Coverage by", feature),
           x = feature) +
      theme_minimal()
  )
}
```

#### Cek **pesebaran data** untuk setiap *src_area*, *hour*, *wday*, dan *coverage*
```{r message=FALSE}
for (cov in c("both", "insufficient", "sufficient")){
  heatmap_data <- train %>%
    group_by(src_area, dhour, wday, coverage) %>%
    summarise(count = n()) %>%
    ungroup()
  
  if (cov != "both"){
    heatmap_data <- heatmap_data %>%
      filter(coverage == cov)
  }

  print(
    ggplot(heatmap_data, aes(x = dhour, y = wday, fill = count)) +
      geom_tile() +
      facet_grid(. ~ src_area) +
      scale_fill_gradient(low = "pink", high = "brown") +  # You can choose different color palettes here
      labs(title = paste("Coverage:", cov),
           x = "dhour",
           y = "wday",
           fill = "Count") +
      theme_minimal()
  )
}
```
                                                                        
## CROSS VALIDATION
                                                                        
#### **Split data** untuk training dan testing
Karena baris data kita cukup sedikit, kita akan split data kita dengan proporsi 80/20
```{r warning=FALSE}
# Set seed, biar acakannya tidak berubah-ubah
RNGkind(sample.kind = "Rounding")
set.seed(1)

# Ambil index untuk data train
indices <- sample(nrow(train), nrow(train) * 0.8)

# Subset data train dan test
train_data <- train[indices, ]
test_data <- train[-indices, ]

# Split features dan target
X_train <- train_data %>% select(-coverage)
y_train <- train_data$coverage
X_test <- test_data %>% select(-coverage)
y_test <- test_data$coverage
```
                                                                          
## MODEL FITTING

#### Metrics
**Akurasi** mengukur sejauh mana model klasifikasi benar dalam memprediksi semua jenis kasus, baik yang positif maupun negatif.
**Sensitivity** mengukur kemampuan model untuk mengidentifikasi dengan benar kasus dari kelas positif ("insufficient"). Sensitivity yang tinggi berarti model efektif dalam menangkap sebagian besar kasus "insufficient yang akurat. Sensitivity yang rendah berarti model kurang mampu memprediksi kelas positif
**Specificity** mengukur kemampuan model untuk mengidentifikasi dengan benar kasus dari kelas negatif. Spesicificity yang tinggi menunjukkan bahwa model bagus dalam mengenali kasus-kasus kelas negatif ("sufficient"), tetapi mungkin tidak sebaik itu dalam kasus positif.
  
Pada kasus ini, kita akan menggunakan score metrik pada prediksi data test sebagai pembanding agar score yang dibandingkan **bukanlah hasil overfittin**.
Untuk kasus ini, karena saya rasa kedua kondisi (FN & FP) sama-sama penting, maka saya akan menggunakan **accuracy** sebagai metrik utama. Selanjutnya, saya akan melihat keseimbangan antara sensitivity dan specificity.

#### Algoritma **Naive Bayes**
Karena cocok dengan kasus kita dan **komputasi yang sangat cepat**, kita akan mencoba algoritma naive bayes sebagai percobaan pertama,
```{r}
# Train model naive bayes
model_nb <- naiveBayes(x = X_train, # Data features
                       y = y_train, # Data target
                       laplace = 1) # Set laplace = 1 untuk smoothing untuk mencegah terdapat probabilitas nol

# Prediksi data test menggunakan model naive bayes kita
pred_nb <- predict(model_nb, X_test)

# Evaluasi model naive bayes kita menggunakan confusion matrix
confusionMatrix(pred_nb, y_test)
```
Kita akan menggunakan score metrik pada prediksi data test sebagai pembanding agar score yang dibandingkan bukanlah hasil overfitting

#### Algoritma **Decision Tree Classifier**
Selain algoritma naive bayes, algoritma yang **cocok dengan kasus kita** adalah decision tree. Mari kita coba
```{r}
# Train model decision tree dengan mengatur control-nya agar modelnya lebih spesifik
model_dt <- ctree(coverage ~ .,
                  train_data,
                  control = ctree_control(mincriterion = 0.35,  # Set mincriterion = 0.35 agar node lebih mudah terbagi
                                          minsplit = 5,      # Set minsplit = 5 agar untuk syarat minimun split
                                          minbucket = 3))    # Set minbucket 3 sebagai syarat minimum pembuatan node baru

# Prediksi data test mengguanakan model decision tree kita
pred_dt <- predict(model_dt, X_test)

# Evaluasi model decision tee kita menggunakan confusion matrix
confusionMatrix(pred_dt, y_test)
```

#### Algoritma **Random Forest**
Karena model decision tree kita memiliki performa yang cukup bagus, langkah baiknya adalah mencoba algoritma random forest
```{r warning=FALSE}
RNGkind(sample.kind = "Rounding")
set.seed(1)

# Atur metode k-fold cross validation
ctrl <- trainControl(method = "repeatedcv",
                     number = 5, # Jumlah folds
                     repeats = 7) # Jumlah repetisi pelaksanaan cross-validation

# Awalnya, saya mengatur parameter number = 3 dan repeats = 5. Setelah saya atur number = 5 dan repeats = 7, performanya sedikit meningkat

# Train model random forest kita dengan control k-fold yang sudah kita atur
model_rf <- train(x = X_train, # Features
                  y = y_train, # Target
                  trControl = ctrl) # Control

# Prediksi data test menggunakan model random forest kita
pred_rf <- predict(model_rf, X_test)

# Evaluasi model random forest kita menggunakan confusion matrix
confusionMatrix(pred_rf, y_test)
```

                                                                        
## TEST PREDICTING

#### **Baca data** test                                                                      
```{r}
test_raw <- read.csv("data_input/data-test.csv")

test_raw %>% head()
```

#### **Extract attributes** yang dibutuhkan untuk melakukan prediksi
```{r}
test <- test_raw %>%
  select(-coverage) %>% 
  mutate(src_area = as.factor(src_area),
         datetime = ymd_hms(datetime),
         wday = as.factor(wday(datetime)),
         dhour = as.factor(hour(datetime)))

test %>% head(4)
```

#### **Prediksi** data test dengan 3 model kita
```{r}
test$coverage_nb <- predict(model_nb, test)
test$coverage_dt <- predict(model_dt, test)
test$coverage_rf <- predict(model_rf, test)

test %>% head()
```
Kita akan coba melihat performa setiap model kita pada submisi algoritma.

#### Masukkan ke csv **submission** dan save untuk disubmit
```{r}
# Prediksi naive bayes
submission <- test_raw %>% mutate(coverage = test$coverage_nb)
write.csv(submission, "submission-ardian-nb.csv")

# Predikisi decision tree
submission <- test_raw %>% mutate(coverage = test$coverage_dt)
write.csv(submission, "submission-ardian-dt.csv")

# Prediksi random forest
submission <- test_raw %>% mutate(coverage = test$coverage_rf)
write.csv(submission, "submission-ardian-rf.csv")
```

Setelah dibandingkan di submisi, model decission tree menjadi model terbaik dengan score berikut:
- Accuracy: 82%
- Recall: 89%
- Precision: 81%
- Specificity: 74%

#### Train **seluruh data**
Karena kita sudah tahu model terbaik kita yang mana, kita akan train model yang sama namun dengan keselurahan data yang kita punya, dengan harapan performa model kita meningkat
```{r}
model_dt_full <- ctree(coverage ~ .,
                  train,
                  control = ctree_control(mincriterion = 0.3,  
                                          minsplit = 2,      
                                          minbucket = 1))  

pred_dt_full <- predict(model_dt_full, train)

confusionMatrix(pred_dt_full, train$coverage)

# Prediksi random forest
submission <- test_raw %>% mutate(coverage = test$coverage_nb)
write.csv(submission, "submission-ardian-dt-full.csv")
```
Mari kita coba submit dan lihat performanya, tapi besok😁

## INTERPRETATION
                                                                       
```{r}

```

## CONCLUSION
                                                                           
##### **Apakah tujuan saya tercapai?**
  Ya, saya berhasil menghasilkan model dengan performa yang memuaskan. Model yang dibuat memiliki akurasi yang baik (82%), serta sensitivitas (recall) yang tinggi (89%), dan presisi yang layak (81%). Selain itu, spesifisitas model juga sebesar 74%, yang menunjukkan kemampuannya dalam mengidentifikasi dengan baik kasus-kasus negatif.

##### **Apakah masalah ini dapat diselesaikan dengan machine learning?**
  Ya, masalah prediksi kecukupan driver pada lokasi tertentu dan waktu tertentu merupakan masalah yang dapat diselesaikan dengan baik menggunakan machine learning. Model decision tree yang Anda gunakan telah memberikan hasil yang bagus dalam mengklasifikasikan kasus-kasus "insufficient" dan "sufficient" pada lokasi dan waktu tertentu.

##### **Model apa yang Anda gunakan dan bagaimana performanya?**
  Model yang digunakan adalah Decision Tree Classifier. Model ini berhasil mencapai akurasi 82%, yang berarti sekitar 82% prediksi yang dilakukan oleh model sesuai dengan kenyataan. Performa yang lebih penting lagi terlihat dalam recall (89%), yang mengindikasikan kemampuan model dalam menangkap sebagian besar kasus "insufficient" yang sebenarnya. Presisi yang mencapai 81% juga menunjukkan bahwa ketika model memprediksi "insufficient," prediksinya cenderung benar. Spesifisitas sebesar 74% menunjukkan kemampuan model dalam mengidentifikasi "sufficient" dengan baik.

##### **Apa potensi implementasi bisnis dari proyek Capstone Anda?**
  Potensi implementasi bisnis dari proyek Capstone ini sangat menjanjikan. Dengan model ini, Anda dapat membantu mengoptimalkan alokasi driver pada lokasi dan waktu tertentu. Misalnya, dengan memprediksi kecukupan driver, perusahaan dapat mengambil langkah-langkah yang lebih baik dalam mengatur penjadwalan driver, menghindari kekurangan driver, dan meningkatkan efisiensi layanan. Hal ini dapat mengurangi ketidaknyamanan pelanggan akibat keterlambatan atau ketidaktersediaan driver. Selain itu, analisis lebih lanjut dari output model ini juga dapat memberikan wawasan berharga untuk pengambilan keputusan dalam mengoptimalkan sumber daya dan meningkatkan pengalaman pelanggan.



